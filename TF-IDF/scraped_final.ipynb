{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10a9d0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation (synthetic retrieval):\n",
      "         n_queries: 200.0000\n",
      "          top1_acc: 0.7850\n",
      "          top5_acc: 0.9100\n",
      "             mrr@5: 0.8319\n",
      "       precision@5: 0.1820\n",
      "          recall@5: 0.9100\n",
      "              f1@5: 0.3033\n",
      "  overall_accuracy: 0.8475\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "import webbrowser\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ML / NLP\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# GUI\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "DATASETS = [\n",
    "    r\"C:\\Users\\MANASVI\\Desktop\\Hybrid recipe generator\\final_indian_recipes.csv\"\n",
    "]\n",
    "TOP_K_DEFAULT = 5\n",
    "RANDOM_SEED = 42\n",
    "PAGE_SIZE = 5  # items per page in GUI\n",
    "\n",
    "# Ingredient synonym / alias mapping\n",
    "SYNONYM_MAP_PHRASES: Dict[str, str] = {\n",
    "    r\"\\bcapsicum\\b\": \"bell pepper\",\n",
    "    r\"\\bmirchi\\b\": \"chili\",\n",
    "    r\"\\bchilli(es)?\\b\": \"chili\",\n",
    "    r\"\\bchilies\\b\": \"chili\",\n",
    "    r\"\\bgreen chili(es)?\\b\": \"chili\",\n",
    "    r\"\\bred chili(es)?\\b\": \"chili\",\n",
    "    r\"\\bcoriander leaves\\b\": \"coriander\",\n",
    "    r\"\\bdhania\\b\": \"coriander\",\n",
    "    r\"\\bcilantro\\b\": \"coriander\",\n",
    "    r\"\\bjeera\\b\": \"cumin\",\n",
    "    r\"\\bzeera\\b\": \"cumin\",\n",
    "    r\"\\bhari mirch\\b\": \"chili\",\n",
    "    r\"\\bhing\\b\": \"asafoetida\",\n",
    "    r\"\\bgur\\b\": \"jaggery\",\n",
    "    r\"\\bgud\\b\": \"jaggery\",\n",
    "    r\"\\bmaida\\b\": \"all purpose flour\",\n",
    "    r\"\\batta\\b\": \"wheat flour\",\n",
    "    r\"\\bdahi\\b\": \"yogurt\",\n",
    "    r\"\\bcurd\\b\": \"yogurt\",\n",
    "    r\"\\bmethi\\b\": \"fenugreek\",\n",
    "    r\"\\bkasuri methi\\b\": \"fenugreek\",\n",
    "    r\"\\baloo\\b\": \"potato\",\n",
    "    r\"\\bbhindi\\b\": \"okra\",\n",
    "    r\"\\btadka\\b\": \"tempering\",\n",
    "}\n",
    "\n",
    "# Minimal noise words\n",
    "NOISE_TOKENS = {\n",
    "    \"fresh\", \"finely\", \"chopped\", \"sliced\", \"diced\", \"ground\", \"powder\",\n",
    "    \"optional\", \"to\", \"taste\", \"medium\", \"large\", \"small\", \"cup\", \"cups\",\n",
    "    \"tsp\", \"tbsp\", \"tablespoon\", \"teaspoon\", \"pinch\", \"piece\", \"pieces\",\n",
    "    \"handful\", \"and\", \"or\", \"of\"\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# Loading & Unification\n",
    "# =========================\n",
    "def load_dataset(path: Union[str, Path]) -> pd.DataFrame:\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Data file not found: {path}\")\n",
    "    if path.suffix.lower() == \".csv\":\n",
    "        df = pd.read_csv(path, encoding=\"utf-8\", engine=\"python\", on_bad_lines=\"skip\")\n",
    "    elif path.suffix.lower() == \".json\":\n",
    "        df = pd.read_json(path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Provide CSV or JSON.\")\n",
    "    df.columns = [re.sub(r\"\\s+\", \"_\", c.strip().lower()) for c in df.columns]\n",
    "    return df\n",
    "\n",
    "\n",
    "def unify_dataset(df: pd.DataFrame, src_name: str) -> pd.DataFrame:\n",
    "    name_col = next((c for c in [\"name\", \"title\", \"recipe_name\", \"dish\", \"recipe\"] if c in df.columns), None)\n",
    "    ing_col = next((c for c in [\"ingredients\", \"ingredient\", \"ingredients_name\", \"translatedingredients\"] if c in df.columns), None)\n",
    "    ins_col = next((c for c in [\"instructions\", \"steps\", \"directions\", \"method\", \"translatedinstructions\"] if c in df.columns), None)\n",
    "    cuisine_col = next((c for c in [\"recipecuisine\", \"cuisine\", \"recipe_cuisine\"] if c in df.columns), None)\n",
    "    source_col = next((c for c in [\"url\", \"source\", \"link\"] if c in df.columns), None)\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"name\": df[name_col] if name_col else [f\"recipe_{i}\" for i in range(len(df))],\n",
    "        \"ingredients\": df[ing_col] if ing_col else \"\",\n",
    "        \"instructions\": df[ins_col] if ins_col else \"\",\n",
    "        \"cuisine\": df[cuisine_col] if cuisine_col else \"\",\n",
    "        \"source\": df[source_col] if source_col else \"\",\n",
    "    })\n",
    "    for c in [\"name\", \"ingredients\", \"instructions\", \"cuisine\", \"source\"]:\n",
    "        out[c] = out[c].astype(str).fillna(\"\")\n",
    "    return out\n",
    "\n",
    "\n",
    "def load_all_datasets(paths: List[str]) -> pd.DataFrame:\n",
    "    dfs = []\n",
    "    for p in paths:\n",
    "        df = load_dataset(p)\n",
    "        df_u = unify_dataset(df, p)\n",
    "        dfs.append(df_u)\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# =========================\n",
    "# Normalization helpers\n",
    "# =========================\n",
    "def apply_synonyms(text: str) -> str:\n",
    "    s = text\n",
    "    for pattern, repl in SYNONYM_MAP_PHRASES.items():\n",
    "        s = re.sub(pattern, repl, s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def normalize_ingredients(value: Any) -> str:\n",
    "    if pd.isna(value):\n",
    "        return \"\"\n",
    "    s = str(value).lower()\n",
    "    s = apply_synonyms(s)\n",
    "    s = re.sub(r\"(\\d+\\/\\d+|\\d+\\.\\d+|\\d+)\", \" \", s)\n",
    "    s = re.sub(r\"[^a-z,;\\s\\-]\", \" \", s)\n",
    "\n",
    "    tokens = [t for t in re.split(r\"[\\s,;]+\", s) if t and t not in NOISE_TOKENS]\n",
    "    s = \" \".join(tokens)\n",
    "    return re.sub(r\"\\s+\", \" \", s).strip()\n",
    "\n",
    "\n",
    "def _tokenize_norm(text: str) -> List[str]:\n",
    "    if not text:\n",
    "        return []\n",
    "    return [t for t in normalize_ingredients(text).split() if t]\n",
    "\n",
    "# =========================\n",
    "# Model\n",
    "# =========================\n",
    "class RecipeRecord:\n",
    "    def __init__(self, idx: int, name: str, ing_text_norm: str, raw_ing: str, raw_ins: str, cuisine: str, source: str):\n",
    "        self.idx = idx\n",
    "        self.name = name\n",
    "        self.ing_text = ing_text_norm\n",
    "        self.raw_ingredients = raw_ing\n",
    "        self.raw_instructions = raw_ins\n",
    "        self.cuisine = cuisine\n",
    "        self.source = source\n",
    "        self.token_set = set(ing_text_norm.split())\n",
    "\n",
    "\n",
    "class IngredientSearch:\n",
    "    def __init__(self):\n",
    "        self.vec_word = TfidfVectorizer(\n",
    "            analyzer=\"word\", ngram_range=(1, 2), min_df=1, strip_accents=\"unicode\", sublinear_tf=True\n",
    "        )\n",
    "        self.vec_char = TfidfVectorizer(\n",
    "            analyzer=\"char\", ngram_range=(3, 6), min_df=1, strip_accents=\"unicode\"\n",
    "        )\n",
    "        self.records: List[RecipeRecord] = []\n",
    "        self.M_word = None\n",
    "        self.M_char = None\n",
    "        self.idf_lookup: Dict[str, float] = {}\n",
    "        self.idf_default: float = 1.0\n",
    "\n",
    "    def fit(self, df: pd.DataFrame):\n",
    "        ing_norm = df[\"ingredients\"].apply(normalize_ingredients)\n",
    "        self.records = [\n",
    "            RecipeRecord(i, str(df.iloc[i][\"name\"]), ing_norm.iloc[i], str(df.iloc[i][\"ingredients\"]), str(df.iloc[i][\"instructions\"]), str(df.iloc[i][\"cuisine\"]), str(df.iloc[i][\"source\"]))\n",
    "            for i in range(len(df))\n",
    "        ]\n",
    "        corpus = [r.ing_text for r in self.records]\n",
    "        self.M_word = self.vec_word.fit_transform(corpus)\n",
    "        self.M_char = self.vec_char.fit_transform(corpus)\n",
    "\n",
    "        vocab = self.vec_word.vocabulary_\n",
    "        idfs = self.vec_word.idf_\n",
    "        self.idf_lookup = {term: float(idfs[idx]) for term, idx in vocab.items()}\n",
    "        self.idf_default = float(np.median(idfs)) if len(idfs) else 1.0\n",
    "        return self\n",
    "\n",
    "    def search(self, query: Union[str, List[str]], top_k: int = 5) -> List[Tuple[float, RecipeRecord]]:\n",
    "        if isinstance(query, list):\n",
    "            tokens_raw = [str(q) for q in query]\n",
    "            tokens = []\n",
    "            for t in tokens_raw:\n",
    "                tokens.extend(_tokenize_norm(t))\n",
    "        else:\n",
    "            tokens = _tokenize_norm(str(query))\n",
    "\n",
    "        tokens = sorted(set(tokens))\n",
    "        if not tokens:\n",
    "            return []\n",
    "\n",
    "        q_text = \" \".join(tokens)\n",
    "\n",
    "        q_w = self.vec_word.transform([q_text])\n",
    "        q_c = self.vec_char.transform([q_text])\n",
    "        s_w = linear_kernel(q_w, self.M_word)[0]\n",
    "        s_c = linear_kernel(q_c, self.M_char)[0]\n",
    "        base_sim = 0.65 * s_w + 0.35 * s_c\n",
    "\n",
    "        denom_idf = sum(self.idf_lookup.get(t, self.idf_default) for t in tokens) + 1e-6\n",
    "        min_match = max(1, int(np.ceil(0.6 * len(tokens))))\n",
    "\n",
    "        results: List[Tuple[float, RecipeRecord, int, float]] = []\n",
    "        token_set_q = set(tokens)\n",
    "\n",
    "        for i, rec in enumerate(self.records):\n",
    "            rec_tokens = rec.token_set\n",
    "            matched = token_set_q & rec_tokens\n",
    "            overlap = len(matched)\n",
    "            coverage_idf = sum(self.idf_lookup.get(t, self.idf_default) for t in matched) / denom_idf\n",
    "\n",
    "            union_sz = len(rec_tokens | token_set_q) + 1e-6\n",
    "            jaccard = overlap / union_sz\n",
    "            length_penalty = 1.0 / (1.0 + 0.02 * max(0, len(rec_tokens) - len(tokens)))\n",
    "\n",
    "            score = float(base_sim[i])\n",
    "            score += 0.75 * coverage_idf\n",
    "            score += 0.10 * jaccard\n",
    "            score += 0.05 * length_penalty\n",
    "\n",
    "            if overlap == len(tokens):\n",
    "                score += 0.50\n",
    "\n",
    "            results.append((score, rec, overlap, coverage_idf))\n",
    "\n",
    "        results.sort(key=lambda x: (x[2], x[0]), reverse=True)\n",
    "\n",
    "        filtered = [r for r in results if r[2] >= min_match]\n",
    "        ranked = filtered if filtered else results\n",
    "\n",
    "        top = ranked[:max(top_k, 50)]\n",
    "        return [(float(score), rec) for score, rec, _, _ in top]\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Evaluation\n",
    "# =========================\n",
    "def evaluate_model(model: IngredientSearch, top_k: int = 5, num_queries: int = 200, seed: int = RANDOM_SEED) -> Dict[str, float]:\n",
    "    rng = random.Random(seed)\n",
    "    candidates = [r for r in model.records if len(r.ing_text.split()) >= 3]\n",
    "    sample = rng.sample(candidates, k=min(num_queries, len(candidates)))\n",
    "\n",
    "    top1 = topk = 0\n",
    "    mrr = 0.0\n",
    "    prec_sum = 0.0\n",
    "    rec_sum = 0.0\n",
    "    f1_sum = 0.0\n",
    "\n",
    "    for r in sample:\n",
    "        toks = r.ing_text.split()\n",
    "        q_len = min(len(toks), rng.randint(3, min(8, len(toks))))\n",
    "        q = \" \".join(rng.sample(toks, q_len))\n",
    "\n",
    "        results = model.search(q, top_k=top_k)\n",
    "        ranks = [i for i, (_, rec) in enumerate(results[:top_k], start=1) if rec.idx == r.idx]\n",
    "        if ranks:\n",
    "            rank = ranks[0]\n",
    "            if rank == 1:\n",
    "                top1 += 1\n",
    "            topk += 1\n",
    "            mrr += 1.0 / rank\n",
    "            p = 1.0 / top_k\n",
    "            r_ = 1.0\n",
    "            prec_sum += p\n",
    "            rec_sum += r_\n",
    "            f1_sum += 2 * p * r_ / (p + r_)\n",
    "\n",
    "    n = max(1, len(sample))\n",
    "    return {\n",
    "        \"n_queries\": float(n),\n",
    "        \"top1_acc\": top1 / n,\n",
    "        f\"top{top_k}_acc\": topk / n,\n",
    "        f\"mrr@{top_k}\": mrr / n,\n",
    "        f\"precision@{top_k}\": prec_sum / n,\n",
    "        f\"recall@{top_k}\": rec_sum / n,\n",
    "        f\"f1@{top_k}\": f1_sum / n,\n",
    "        \"overall_accuracy\": (top1 + topk) / (2 * n)\n",
    "    }\n",
    "\n",
    "# =========================\n",
    "# GUI\n",
    "# =========================\n",
    "class App:\n",
    "    def __init__(self, model: IngredientSearch):\n",
    "        self.model = model\n",
    "        self.results_all: List[Tuple[float, RecipeRecord]] = []\n",
    "        self.cursor = 0\n",
    "\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"Recipe Search (Ingredients â†’ Recipes)\")\n",
    "\n",
    "        tk.Label(self.root, text=\"Enter Ingredients (comma-separated):\").pack(pady=(8, 2))\n",
    "        self.entry = tk.Entry(self.root, width=90)\n",
    "        self.entry.pack(padx=8, pady=(0, 6))\n",
    "\n",
    "        self.btn_frame = tk.Frame(self.root)\n",
    "        self.btn_frame.pack(pady=(0, 4))\n",
    "        tk.Button(self.btn_frame, text=\"Search\", command=self.on_search).pack(side=tk.LEFT, padx=4)\n",
    "        self.show_more_btn = tk.Button(self.btn_frame, text=\"Show More\", state=tk.DISABLED, command=self.on_show_more)\n",
    "        self.show_more_btn.pack(side=tk.LEFT, padx=4)\n",
    "        tk.Button(self.btn_frame, text=\"Clear\", command=self.on_clear).pack(side=tk.LEFT, padx=4)\n",
    "\n",
    "        canvas = tk.Canvas(self.root, height=500)\n",
    "        scrollbar = tk.Scrollbar(self.root, orient=\"vertical\", command=canvas.yview)\n",
    "        self.results_frame = tk.Frame(canvas)\n",
    "        self.results_frame.bind(\"<Configure>\", lambda e: canvas.configure(scrollregion=canvas.bbox(\"all\")))\n",
    "        canvas.create_window((0, 0), window=self.results_frame, anchor=\"nw\")\n",
    "        canvas.configure(yscrollcommand=scrollbar.set)\n",
    "        canvas.pack(side=\"left\", fill=\"both\", expand=True)\n",
    "        scrollbar.pack(side=\"right\", fill=\"y\")\n",
    "\n",
    "        tk.Label(\n",
    "            self.results_frame,\n",
    "            text=\"Type a few ingredients (e.g., 'chicken, garlic, chili, tomato') and press Search.\",\n",
    "            wraplength=600,\n",
    "            justify=\"left\",\n",
    "            fg=\"gray\",\n",
    "        ).pack(pady=10)\n",
    "\n",
    "    def display_results(self, start: int, page_size: int):\n",
    "        end = min(start + page_size, len(self.results_all))\n",
    "        batch = self.results_all[start:end]\n",
    "\n",
    "        for score, rec in batch:\n",
    "            card = tk.Frame(self.results_frame, relief=\"groove\", borderwidth=2, padx=8, pady=6)\n",
    "            card.pack(fill=\"x\", padx=8, pady=6)\n",
    "\n",
    "            # Recipe name\n",
    "            tk.Label(card, text=rec.name, font=(\"Arial\", 12, \"bold\")).pack(anchor=\"w\")\n",
    "\n",
    "            # Cuisine\n",
    "            if rec.cuisine and rec.cuisine.lower() != \"nan\":\n",
    "                tk.Label(card, text=f\"Cuisine: {rec.cuisine}\", fg=\"blue\").pack(anchor=\"w\")\n",
    "\n",
    "            # Ingredients\n",
    "            ing = rec.raw_ingredients.strip()\n",
    "            if ing:\n",
    "                tk.Label(\n",
    "                    card, text=f\"Ingredients:\\n{ing}\",\n",
    "                    wraplength=700, justify=\"left\"\n",
    "                ).pack(anchor=\"w\", pady=(2, 4))\n",
    "\n",
    "            # Instructions\n",
    "            ins = rec.raw_instructions.strip()\n",
    "            if ins:\n",
    "                if re.search(r\"(?i)\\bstep\\s*\\d*\", ins):\n",
    "                    steps = re.split(r\"(?i)\\bstep\\s*\\d*[:\\-]?\\s*\", ins)\n",
    "                    steps = [s.strip() for s in steps if s.strip()]\n",
    "                else:\n",
    "                    steps = re.split(r'(?<=[.!?])\\s+', ins)\n",
    "                    steps = [s.strip() for s in steps if s.strip()]\n",
    "\n",
    "                ins_text = \"\\n\".join([f\"Step {i+1}: {s}\" for i, s in enumerate(steps)])\n",
    "\n",
    "                tk.Label(\n",
    "                    card, text=f\"Instructions:\\n{ins_text}\",\n",
    "                    wraplength=700, justify=\"left\"\n",
    "                ).pack(anchor=\"w\", pady=(2, 4))\n",
    "\n",
    "            # View Source\n",
    "            if rec.source and rec.source.lower() != \"nan\":\n",
    "                link = tk.Label(card, text=\"View Source\", fg=\"green\", cursor=\"hand2\")\n",
    "                link.pack(anchor=\"w\")\n",
    "                link.bind(\"<Button-1>\", lambda e, url=rec.source: webbrowser.open(url))\n",
    "\n",
    "    def on_search(self):\n",
    "        query = self.entry.get().strip()\n",
    "        if not query:\n",
    "            messagebox.showwarning(\"Input Error\", \"Please enter some ingredients.\")\n",
    "            return\n",
    "\n",
    "        for widget in self.results_frame.winfo_children():\n",
    "            widget.destroy()\n",
    "\n",
    "        self.results_all = self.model.search(query, top_k=50)\n",
    "        self.cursor = 0\n",
    "\n",
    "        if not self.results_all:\n",
    "            tk.Label(self.results_frame, text=\"No results. Try different ingredients.\", fg=\"red\").pack(pady=10)\n",
    "            self.show_more_btn.config(state=tk.DISABLED)\n",
    "            return\n",
    "\n",
    "        self.display_results(0, PAGE_SIZE)\n",
    "        self.cursor += PAGE_SIZE\n",
    "        self.show_more_btn.config(state=(tk.NORMAL if self.cursor < len(self.results_all) else tk.DISABLED))\n",
    "\n",
    "    def on_show_more(self):\n",
    "        self.display_results(self.cursor, PAGE_SIZE)\n",
    "        self.cursor += PAGE_SIZE\n",
    "        if self.cursor >= len(self.results_all):\n",
    "            self.show_more_btn.config(state=tk.DISABLED)\n",
    "\n",
    "    def on_clear(self):\n",
    "        for widget in self.results_frame.winfo_children():\n",
    "            widget.destroy()\n",
    "        self.cursor = 0\n",
    "        self.results_all = []\n",
    "        self.show_more_btn.config(state=tk.DISABLED)\n",
    "\n",
    "    def run(self):\n",
    "        self.root.mainloop()\n",
    "\n",
    "# =========================\n",
    "# Main\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    random.seed(RANDOM_SEED)\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "\n",
    "    df_all = load_all_datasets(DATASETS)\n",
    "    model = IngredientSearch().fit(df_all)\n",
    "\n",
    "    metrics = evaluate_model(model, top_k=TOP_K_DEFAULT, num_queries=200)\n",
    "    print(\"\\nEvaluation (synthetic retrieval):\")\n",
    "    for k, v in metrics.items():\n",
    "        if isinstance(v, float):\n",
    "            print(f\"  {k:>16}: {v:.4f}\")\n",
    "        else:\n",
    "            print(f\"  {k:>16}: {v}\")\n",
    "\n",
    "    App(model).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32462c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
